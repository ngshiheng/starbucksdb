name: Scrape latest data

on:
    push:
        branches:
            - "main"
        paths:
            - "**.py"
            - "poetry.lock"
            - ".github/workflows/**"

    workflow_dispatch:
    schedule:
        - cron: "0 0 * * 0" # Every Sunday at 00:00

env:
    PYTHON_VERSION: "3.11"
    POETRY_VERSION: "1.7"
    POETRY_URL: https://install.python-poetry.org

jobs:
    crawl-and-update:
        runs-on: ubuntu-latest
        steps:
            - uses: actions/checkout@v4

            - name: Install poetry & datasette
              run: |
                  pipx install poetry==${{ env.POETRY_VERSION }}
                  pipx install datasette

            - name: Set up python
              uses: actions/setup-python@v5
              with:
                  python-version: ${{ env.PYTHON_VERSION }}
                  cache: poetry
                  cache-dependency-path: poetry.lock

            - name: Set poetry environment
              run: |
                  poetry env use ${{ env.PYTHON_VERSION }}

            - name: Install poetry dependencies
              run: |
                  poetry install --no-root

            - name: Get latest artifact id
              run: |
                  ARTIFACT_ID=$(curl -s "https://api.github.com/repos/${{ github.repository }}/actions/artifacts?per_page=1" | jq '.artifacts[0].id')
                  echo "artifact_id=$ARTIFACT_ID" >> $GITHUB_ENV

            - name: Download artifact
              uses: actions/download-artifact@v4
              with:
                  name: starbucksdb
                  path: ./data/
                  run-id: ${{ env.artifact_id }}
                  github-token: ${{ secrets.GH_PAT  }}
              continue-on-error: true

            - name: Get current date
              run: echo "today=$(date --rfc-3339=date)" >> $GITHUB_ENV

            - name: Restore scrapy cache
              id: scrapy-cache-restore
              uses: actions/cache/restore@v4
              with:
                  path: |
                      .scrapy
                  key: ${{ runner.os }}-pypoetry-${{ hashFiles('**/poetry.lock') }}-${{ env.today  }}

            - name: Run scrapy crawl
              run: poetry run scrapy crawl singapore

            - name: Save scrapy cache
              id: cache-primes-save
              uses: actions/cache/save@v4
              with:
                  path: |
                      .scrapy
                  key: ${{ steps.scrapy-cache-restore.outputs.cache-primary-key }}

            - name: Upload updated artifact
              uses: actions/upload-artifact@v4
              with:
                  name: starbucksdb
                  path: ./data/starbucks.db
                  if-no-files-found: error

            - name: Deploy to vercel
              env:
                  VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
              run: |-
                  datasette install datasette-publish-vercel
                  datasette publish vercel data/starbucks.db  --project=starbucksdb --install=datasette-hashed-urls --install=datasette-cluster-map --token="$VERCEL_TOKEN" --metadata data/metadata.json --setting allow_download off  --setting allow_csv_stream off  --setting max_csv_mb 0 --extra-options "-i"
